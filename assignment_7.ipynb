{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84GqNz8Ztw4G"
   },
   "source": [
    "# Artificial Intelligence\n",
    "# 464/664\n",
    "# Assignment #7\n",
    "\n",
    "## General Directions for this Assignment\n",
    "\n",
    "00. We're using a Jupyter Notebook environment (tutorial available here: https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html),\n",
    "01. Output format should be exactly as requested (it is your responsibility to make sure notebook looks as expected on Gradescope),\n",
    "02. Check submission deadline on Gradescope,\n",
    "03. Rename the file to Last_First_assignment_7,\n",
    "04. Submit your notebook (as .ipynb, not PDF) using Gradescope, and\n",
    "05. Do not submit any other files.\n",
    "\n",
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSN1KpKJtw4K"
   },
   "source": [
    "## Neural Networks: Architecture\n",
    "\n",
    "For this assignment we will explore Neural Networks; in particular, we are going to explore model complexity. We will use the same dataset from Assignment #6 to classify a mushroom as either edible ('e') or poisonous ('p'). You are free to use PyTorch, TensorFlow, scikit-learn -- to name a few resources. The goal is to explore different model complexities (architectures) before declaring a winner. Either start with a simple network and make it more complex; or start with a complex model and pare it down. Either way, your submission should clearly demonstrate your exploration.\n",
    "\n",
    "\n",
    "Your output for each model should look like the output of `cross_validate` from Assignment #6:\n",
    "\n",
    "```\n",
    "Fold: 0\tTrain Error: 15.38%\tValidation Error: 0.00%\n",
    "Fold: 1\n",
    "...\n",
    "\n",
    "Mean(Std. Dev.) over all folds:\n",
    "-------------------------------\n",
    "Train Error: 100.00%(0.00%) Test Error: 100.00%(0.00%)\n",
    "```\n",
    "\n",
    "Notice that \"Test Error\" has been replaced by \"Validation Error.\" Split your dataset into train, test, and validation sets.\n",
    "\n",
    "\n",
    "Start with a simple network. Train using the train set. Observe model's performance using the validation set.\n",
    "\n",
    "\n",
    "Increase the complexity of your network. Train using the train set. Observe model's performance using the validation set.\n",
    "\n",
    "\n",
    "Model complexity in Assignment #6 was depth limit. You can think of it here as the architecture of the network (number of layers and units per layer). Try at least three different network architectures.\n",
    "\n",
    "\n",
    "We're trying to find a model complexity that generalizes well. (Recall high bias vs high variance discussion in class.)\n",
    "\n",
    "\n",
    "Pick the network architecture that you deem best. Use the test set to report your winning model's performance. This is the ONLY time you use the test set.\n",
    "\n",
    "\n",
    "Try at least three different models; more importantly, document your process: what the results were, how the winning model was determined, what was the winning model's performance on the test data. Clearly highlight these items to receive full credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3-RPRoiXtw4L"
   },
   "outputs": [],
   "source": [
    "# Implementation and exploration.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_folds`\n",
    "\n",
    "The `create_folds` function splits input data (`x_data` and `y_data`) into `num_folds` for cross-validation.\n",
    "\n",
    "#### Parameters:\n",
    "- `x_data`: A dictionary where each key is a feature and the value is a list or array of feature values.\n",
    "- `y_data`: A list or array of target labels corresponding to the features in `x_data`.\n",
    "- `num_folds`: The number of folds for cross-validation.\n",
    "\n",
    "#### Returns:\n",
    "- `x_data_folds`: A list of `num_folds` dictionaries, each containing a subset of the features.\n",
    "- `y_data_folds`: A list of `num_folds` lists or arrays, each containing a subset of the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(x_data, y_data, num_folds):\n",
    "    # Validate input data\n",
    "    assert len(x_data) > 0 and len(y_data) > 0\n",
    "    assert len(list(x_data.values())[0]) == len(y_data)\n",
    "\n",
    "    # Create folds\n",
    "    num_samples_per_fold, remainder = divmod(len(y_data), num_folds)\n",
    "    x_data_folds, y_data_folds = [], []\n",
    "\n",
    "    for fold_index in range(num_folds):\n",
    "        start_index = fold_index * num_samples_per_fold + min(fold_index, remainder)\n",
    "        end_index = (fold_index + 1) * num_samples_per_fold + min(fold_index + 1, remainder)\n",
    "\n",
    "        x_fold = {feature: values[start_index:end_index] for feature, values in x_data.items()}\n",
    "        y_fold = y_data[start_index:end_index]\n",
    "\n",
    "        x_data_folds.append(x_fold)\n",
    "        y_data_folds.append(y_fold)\n",
    "\n",
    "    return x_data_folds, y_data_folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `test_model`\n",
    "\n",
    "The `test_model` function evaluates the performance of a trained model on a test dataset (`x_test` and `y_test`).\n",
    "\n",
    "#### Parameters:\n",
    "- `model`: The trained model to be evaluated.\n",
    "- `x_test`: The feature data for testing.\n",
    "- `y_test`: The true target labels corresponding to `x_test`.\n",
    "\n",
    "#### Returns:\n",
    "- A float representing the accuracy of the model, calculated as the ratio of correct predictions to the total number of test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    # Track performance\n",
    "    correct = 0\n",
    "    total = len(y_test)\n",
    "\n",
    "    # Get predictions\n",
    "    preds = [p for labels in model.predict(x_test, verbose=0) for p in labels]\n",
    "    true_vals = y_test.to_list()\n",
    "\n",
    "    # Compare predictions with true values\n",
    "    for i in range(total):\n",
    "        if true_vals[i] == round(preds[i]):\n",
    "            correct += 1\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_model`\n",
    "\n",
    "The `train_model` function builds, compiles, and trains a neural network model based on the provided training data, validation data, and hyperparameters.\n",
    "\n",
    "#### Parameters:\n",
    "- `x_tr`: A dictionary where each key is a feature name and the value is the training data for that feature.\n",
    "- `y_tr`: A list or array of target labels corresponding to `x_tr`.\n",
    "- `epochs`: The number of epochs to train the model.\n",
    "- `x_val`: A dictionary of validation feature data, corresponding to `x_tr`.\n",
    "- `y_val`: A list or array of validation target labels, corresponding to `x_val`.\n",
    "- `complexity`: A list of integers specifying the number of units in each hidden layer.\n",
    "- `act`: The activation function to be used in the hidden layers.\n",
    "- `opt`: The optimizer to be used for training the model.\n",
    "- `loss_fn`: The loss function to be used for training the model.\n",
    "\n",
    "#### Returns:\n",
    "- `model`: The trained model.\n",
    "- `hist`: The history object containing details about the training process, including the loss and accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_tr, y_tr, epochs, x_val, y_val, complexity, act, opt, loss_fn):\n",
    "    # Build inputs\n",
    "    inputs = {name: tf.keras.Input(shape=(1,), name=name, dtype=tf.string) for name in x_tr.keys()}\n",
    "\n",
    "    # Preprocess inputs\n",
    "    enc_feats = []\n",
    "    for name in inputs.keys():\n",
    "        # String lookup layer\n",
    "        lookup = layers.StringLookup(output_mode='one_hot')\n",
    "        lookup.adapt(x_tr[name])\n",
    "        enc_feats.append(lookup(inputs[name]))\n",
    "\n",
    "    # Concatenate all features\n",
    "    all_feats = layers.concatenate(enc_feats)\n",
    "\n",
    "    # Build model with specified complexity\n",
    "    x = all_feats\n",
    "    for i, units in enumerate(complexity):\n",
    "        x = layers.Dense(units, activation=act, name=f'dense_{i}')(x)\n",
    "    out = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    # Fit model\n",
    "    hist = model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=epochs, verbose=0)\n",
    "\n",
    "    return model, hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### `cross_validate`\n",
    "\n",
    "The `cross_validate` function performs k-fold cross-validation to evaluate a model's performance across multiple folds.\n",
    "\n",
    "#### Parameters:\n",
    "- `complexity`: A list specifying the number of units in each hidden layer.\n",
    "- `x_folds`: A list of `n_folds` dictionaries, where each dictionary contains feature data for a fold.\n",
    "- `y_folds`: A list of `n_folds` arrays or lists, where each list contains target labels for a fold.\n",
    "- `act`: The activation function used in the hidden layers.\n",
    "- `opt`: The optimizer used for training the model.\n",
    "- `loss`: The loss function used for training the model.\n",
    "- `epochs`: The number of epochs for model training.\n",
    "- `x_train_feats`: The feature set for training.\n",
    "- `n_folds`: The number of folds for cross-validation.\n",
    "\n",
    "#### Returns:\n",
    "- `model`: The trained model from the final fold.\n",
    "- `mean_val_err`: The mean validation error across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(complexity, x_folds, y_folds, act, opt, loss, epochs, x_train_feats, n_folds):\n",
    "\n",
    "    # Create data structures to log performance\n",
    "    tr_errs, val_errs = [], []\n",
    "    print(f\"\\nEvaluating model with layers: {complexity}\")\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        # Prepare validation data\n",
    "        x_val, y_val = x_folds[i], y_folds[i]\n",
    "\n",
    "        # Prepare training data by combining other folds\n",
    "        x_train = {key: np.concatenate([x_folds[j][key] for j in range(n_folds) if j != i]) for key in x_train_feats.columns}\n",
    "        y_train = np.concatenate([y_folds[j] for j in range(n_folds) if j != i])\n",
    "\n",
    "        # Build and evaluate the model\n",
    "        model, hist = train_model(\n",
    "            x_train, y_train, epochs, x_val, y_val, complexity, act, opt, loss\n",
    "        )\n",
    "\n",
    "        # Calculate errors\n",
    "        tr_errs.append(100 * (1 - np.mean(hist.history['accuracy'])))\n",
    "        val_errs.append(100 * (1 - np.mean(hist.history['val_accuracy'])))\n",
    "\n",
    "    # Display fold results\n",
    "    for i, (tr_err, val_err) in enumerate(zip(tr_errs, val_errs)):\n",
    "        print(f\"Fold: {i}    Train Error: {tr_err:.2f}%    Validation Error: {val_err:.2f}%\")\n",
    "\n",
    "    # Report mean and std dev\n",
    "    mean_tr_err, std_tr_err = np.mean(tr_errs), np.std(tr_errs)\n",
    "    mean_val_err, std_val_err = np.mean(val_errs), np.std(val_errs)\n",
    "\n",
    "    print(\"\\nMean(Std. Dev.) over all folds for this model:\")\n",
    "    print(\"-------------------------------\")\n",
    "    print(f\"Train Error: {mean_tr_err:.2f}%({std_tr_err:.2f}%) Validation Error: {mean_val_err:.2f}%({std_val_err:.2f}%)\")\n",
    "\n",
    "    return model, mean_val_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `load_and_shuffle_data`\n",
    "\n",
    "The `load_and_shuffle_data` function loads a CSV file containing mushroom data, assigns column names, and shuffles the data.\n",
    "\n",
    "#### Parameters:\n",
    "- `filepath`: The path to the CSV file containing the dataset.\n",
    "\n",
    "#### Returns:\n",
    "- A shuffled `DataFrame` containing the mushroom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_shuffle_data(filepath):\n",
    "    df = pd.read_csv(filepath, names=[\"poisonous\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\",\n",
    "                                       \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\", \n",
    "                                       \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \n",
    "                                       \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \n",
    "                                       \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"])\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `prepare_features_labels`\n",
    "\n",
    "The `prepare_features_labels` function prepares the features and labels for machine learning.\n",
    "\n",
    "#### Parameters:\n",
    "- `df`: A `DataFrame` containing the dataset.\n",
    "\n",
    "#### Returns:\n",
    "- `X`: A `DataFrame` containing the feature columns.\n",
    "- `y`: A Series containing the target labels (encoded as 0 for edible and 1 for poisonous).\n",
    "- `X_dict`: A dictionary with feature names as keys and the corresponding values as arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_labels(df):\n",
    "    X = df.copy()\n",
    "    y = X.pop('poisonous').map({'e': 0, 'p': 1})\n",
    "    X_dict = {col: np.array(val) for col, val in X.items()}\n",
    "    return X, y, X_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `split_data`\n",
    "\n",
    "The `split_data` function splits the dataset into training and testing sets.\n",
    "\n",
    "#### Parameters:\n",
    "- `X`: The feature set.\n",
    "- `y`: The target labels.\n",
    "\n",
    "#### Returns:\n",
    "- `X_train`: The training feature set.\n",
    "- `X_test`: The testing feature set.\n",
    "- `y_train`: The training target labels.\n",
    "- `y_test`: The testing target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `format_for_tensorflow`\n",
    "\n",
    "The `format_for_tensorflow` function formats the data for use in TensorFlow models.\n",
    "\n",
    "#### Parameters:\n",
    "- `X_train`: The training feature set.\n",
    "- `X_test`: The testing feature set.\n",
    "\n",
    "#### Returns:\n",
    "- A dictionary with \"train\" and \"test\" keys, each containing a dictionary of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_tensorflow(X_train, X_test):\n",
    "    return {\n",
    "        \"train\": {col: np.array(val) for col, val in X_train.items()},\n",
    "        \"test\": {col: np.array(val) for col, val in X_test.items()}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `run_cross_validation`\n",
    "\n",
    "The `run_cross_validation` function runs cross-validation with multiple model complexities to determine the best-performing model.\n",
    "\n",
    "#### Parameters:\n",
    "- `complexities`: A list of different layer complexities to test.\n",
    "- `X_folds`: A list of feature data for each fold.\n",
    "- `y_folds`: A list of target labels for each fold.\n",
    "- `activation`: The activation function to use in the model.\n",
    "- `optimizer`: The optimizer to use for training.\n",
    "- `loss_fn`: The loss function to use for training.\n",
    "- `epochs`: The number of epochs to train the model.\n",
    "- `X_train`: The training feature set.\n",
    "- `folds`: The number of folds for cross-validation.\n",
    "\n",
    "#### Returns:\n",
    "- `best_model`: The best-performing model.\n",
    "- `best_complexity`: The complexity (layer structure) of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_validation(complexities, X_folds, y_folds, activation, optimizer, loss_fn, epochs, X_train, folds):\n",
    "    best_val_err = float('inf')\n",
    "    best_model = None\n",
    "    best_complexity = None\n",
    "\n",
    "    for complexity in complexities:\n",
    "        model, val_err = cross_validate(complexity, X_folds, y_folds, activation, optimizer, loss_fn, epochs, X_train, folds)\n",
    "        if val_err < best_val_err:\n",
    "            best_val_err = val_err\n",
    "            best_model = model\n",
    "            best_complexity = complexity\n",
    "            \n",
    "    return best_model, best_complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `main`\n",
    "\n",
    "\n",
    "The function loads the dataset, prepares the data, performs cross-validation, and evaluates the best model.\n",
    "\n",
    "#### Returns:\n",
    "- None (it runs the experiment and prints the results).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model with layers: [6]\n",
      "Fold: 0    Train Error: 10.18%    Validation Error: 3.87%\n",
      "Fold: 1    Train Error: 6.59%    Validation Error: 2.64%\n",
      "Fold: 2    Train Error: 8.20%    Validation Error: 3.14%\n",
      "Fold: 3    Train Error: 11.46%    Validation Error: 4.37%\n",
      "Fold: 4    Train Error: 5.17%    Validation Error: 1.48%\n",
      "Fold: 5    Train Error: 9.50%    Validation Error: 4.74%\n",
      "Fold: 6    Train Error: 10.88%    Validation Error: 4.19%\n",
      "Fold: 7    Train Error: 11.39%    Validation Error: 2.65%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 9.17%(2.17%) Validation Error: 3.39%(1.03%)\n",
      "\n",
      "Evaluating model with layers: [12, 6]\n",
      "Fold: 0    Train Error: 7.05%    Validation Error: 1.17%\n",
      "Fold: 1    Train Error: 7.56%    Validation Error: 1.54%\n",
      "Fold: 2    Train Error: 5.68%    Validation Error: 1.17%\n",
      "Fold: 3    Train Error: 6.02%    Validation Error: 1.35%\n",
      "Fold: 4    Train Error: 4.42%    Validation Error: 0.62%\n",
      "Fold: 5    Train Error: 5.07%    Validation Error: 0.55%\n",
      "Fold: 6    Train Error: 4.73%    Validation Error: 0.92%\n",
      "Fold: 7    Train Error: 8.06%    Validation Error: 1.17%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 6.08%(1.27%) Validation Error: 1.06%(0.32%)\n",
      "\n",
      "Evaluating model with layers: [18, 12, 6]\n",
      "Fold: 0    Train Error: 4.69%    Validation Error: 0.25%\n",
      "Fold: 1    Train Error: 6.57%    Validation Error: 0.98%\n",
      "Fold: 2    Train Error: 5.07%    Validation Error: 0.25%\n",
      "Fold: 3    Train Error: 2.82%    Validation Error: 0.37%\n",
      "Fold: 4    Train Error: 4.04%    Validation Error: 0.25%\n",
      "Fold: 5    Train Error: 4.14%    Validation Error: 0.25%\n",
      "Fold: 6    Train Error: 7.73%    Validation Error: 0.37%\n",
      "Fold: 7    Train Error: 5.71%    Validation Error: 0.37%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 5.10%(1.45%) Validation Error: 0.38%(0.23%)\n",
      "Best model complexity: [18, 12, 6]\n",
      "Test Error of the best model: 0.00%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load and prepare data\n",
    "    df = load_and_shuffle_data(\"agaricus-lepiota.data\")\n",
    "    X, y, X_dict = prepare_features_labels(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    data_dicts = format_for_tensorflow(X_train, X_test)\n",
    "\n",
    "    # Create folds for cross-validation\n",
    "    folds = 8\n",
    "    X_folds, y_folds = create_folds(data_dicts[\"train\"], y_train.values, folds)\n",
    "\n",
    "    # Define model complexities\n",
    "    complexities = [\n",
    "        [6], [12, 6],[18, 12, 6],\n",
    "    ]\n",
    "\n",
    "    # Experiment with models\n",
    "    activation, optimizer, loss_fn, epochs = 'relu', 'adam', 'mean_squared_error', 2\n",
    "    best_model, best_complexity = run_cross_validation(complexities, X_folds, y_folds, activation, optimizer, loss_fn, epochs, X_train, folds)\n",
    "\n",
    "    # Evaluate best model\n",
    "    print(f\"Best model complexity: {best_complexity}\")\n",
    "    test_acc = test_model(best_model, data_dicts[\"test\"], y_test)\n",
    "    test_err = 100 * (1 - test_acc)\n",
    "    print(f\"Test Error of the best model: {test_err:.2f}%\")\n",
    "\n",
    "# Run the experiment\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks: Architecture Exploration for Mushroom Classification\n",
    "\n",
    "In this assignment, the goal was to explore different neural network architectures for classifying mushrooms as either edible ('e') or poisonous ('p'). We experimented with three different network complexities to find the best model that generalizes well to new data. The dataset from Assignment #6 was used, and we employed cross-validation to evaluate each modelâ€™s performance. Finally, the best model was selected, and its performance on the test set was reported.\n",
    "\n",
    "### Methodology:\n",
    "We experimented with three different network architectures, each with a varying number of layers and units. The complexity of each network was increased in successive models to understand how they affect generalization (i.e., their ability to perform well on unseen data). The architectures tested were:\n",
    "\n",
    "1. **Model 1:** [6] - A simple network with one hidden layer containing 6 units.\n",
    "2. **Model 2:** [12, 6] - A more complex network with two hidden layers: 12 units in the first and 6 in the second.\n",
    "3. **Model 3:** [18, 12, 6] - The most complex network with three hidden layers: 18 units in the first, 12 in the second, and 6 in the third.\n",
    "\n",
    "### Evaluation Process:\n",
    "\n",
    "#### Step 1: Cross-validation\n",
    "Each model was evaluated using 8-fold cross-validation, where the dataset was split into training and validation sets. For each fold, we computed the training error and validation error. We also calculated the mean and standard deviation of errors across all folds.\n",
    "\n",
    "#### Step 2: Model Complexity and Bias-Variance Tradeoff\n",
    "We were particularly concerned with **bias** (underfitting) and **variance** (overfitting):\n",
    "- **Model 1** (simple) was expected to have higher bias, as it might not be complex enough to capture the relationships in the data.\n",
    "- **Model 2** (medium complexity) should strike a better balance between bias and variance.\n",
    "- **Model 3** (complex) was expected to have lower bias but potentially higher variance, especially if it overfits the training data.\n",
    "\n",
    "#### Step 3: Model Selection\n",
    "Based on cross-validation results, we chose the model that generalizes best, meaning the one with the lowest validation error.\n",
    "\n",
    "### Results:\n",
    "\n",
    "#### **Model 1: [6]**\n",
    "- **Train Errors:** \n",
    "  - Mean: 9.17%, Std. Dev.: 2.17%\n",
    "- **Validation Errors:** \n",
    "  - Mean: 3.39%, Std. Dev.: 1.03%\n",
    "- **Interpretation:** While this model performed reasonably well, the validation error was somewhat high, indicating potential underfitting.\n",
    "\n",
    "#### **Model 2: [12, 6]**\n",
    "- **Train Errors:** \n",
    "  - Mean: 6.08%, Std. Dev.: 1.27%\n",
    "- **Validation Errors:** \n",
    "  - Mean: 1.06%, Std. Dev.: 0.32%\n",
    "- **Interpretation:** This model showed a better balance between train and validation errors, with lower error on both compared to Model 1. It likely has a better fit to the data.\n",
    "\n",
    "#### **Model 3: [18, 12, 6]**\n",
    "- **Train Errors:** \n",
    "  - Mean: 5.10%, Std. Dev.: 1.45%\n",
    "- **Validation Errors:** \n",
    "  - Mean: 0.38%, Std. Dev.: 0.23%\n",
    "- **Interpretation:** Model 3 achieved the lowest validation error, indicating that it generalizes extremely well. The model is complex enough to capture the underlying patterns in the data without overfitting.\n",
    "\n",
    "### Best Model Selection:\n",
    "**Model 3 ([18, 12, 6])** was selected as the best model based on the following reasons:\n",
    "- It had the lowest validation error (0.38%), indicating the best generalization ability.\n",
    "- It did not suffer from overfitting, as evidenced by the low validation error despite its complexity.\n",
    "  \n",
    "### Test Set Performance:\n",
    "Once Model 3 was selected, we evaluated its performance on the test set (the only time this set was used). The results were as follows:\n",
    "- **Test Error:** **0.00%**\n",
    "- **Interpretation:** The test error being 0.00% confirms that Model 3 generalizes exceptionally well to unseen data.\n",
    "\n",
    "### Conclusion:\n",
    "- **Winning Model:** Model 3 with the architecture [18, 12, 6] was the best performing model.\n",
    "- **Test Performance:** Model 3 achieved **0.00% test error**, showing excellent generalization.\n",
    "- **Bias vs. Variance:** Model 3 achieved a great balance between bias and variance, fitting the data well without overfitting.\n",
    "\n",
    "This exploration successfully demonstrated how increasing model complexity can reduce bias, but it is crucial to find the right architecture that minimizes both bias and variance to ensure the model generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeaSsuWCt2dI"
   },
   "source": [
    "## Experiment: Activation Function and Optimizer\n",
    "Modify the 1) Activation function 2) Optimizer of any chosen model. Try at least one model for each modified component.\n",
    "\n",
    "Explain the motivation behind the modifications you made.\n",
    "\n",
    "Explore the effects on the performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WaYqkeqQyanB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model with layers: [6]\n",
      "Fold: 0    Train Error: 20.33%    Validation Error: 10.70%\n",
      "Fold: 1    Train Error: 11.31%    Validation Error: 7.13%\n",
      "Fold: 2    Train Error: 18.17%    Validation Error: 11.01%\n",
      "Fold: 3    Train Error: 13.60%    Validation Error: 8.44%\n",
      "Fold: 4    Train Error: 11.15%    Validation Error: 5.79%\n",
      "Fold: 5    Train Error: 19.40%    Validation Error: 10.65%\n",
      "Fold: 6    Train Error: 16.42%    Validation Error: 14.22%\n",
      "Fold: 7    Train Error: 19.89%    Validation Error: 10.53%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 16.28%(3.55%) Validation Error: 9.81%(2.45%)\n",
      "\n",
      "Evaluating model with layers: [12, 6]\n",
      "Fold: 0    Train Error: 12.10%    Validation Error: 10.33%\n",
      "Fold: 1    Train Error: 19.68%    Validation Error: 12.36%\n",
      "Fold: 2    Train Error: 19.82%    Validation Error: 10.21%\n",
      "Fold: 3    Train Error: 12.41%    Validation Error: 8.13%\n",
      "Fold: 4    Train Error: 18.71%    Validation Error: 13.24%\n",
      "Fold: 5    Train Error: 16.27%    Validation Error: 11.64%\n",
      "Fold: 6    Train Error: 13.72%    Validation Error: 9.54%\n",
      "Fold: 7    Train Error: 9.95%    Validation Error: 6.90%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 15.33%(3.57%) Validation Error: 10.29%(1.99%)\n",
      "\n",
      "Evaluating model with layers: [18, 12, 6]\n",
      "Fold: 0    Train Error: 14.69%    Validation Error: 9.72%\n",
      "Fold: 1    Train Error: 15.26%    Validation Error: 8.55%\n",
      "Fold: 2    Train Error: 15.87%    Validation Error: 12.36%\n",
      "Fold: 3    Train Error: 16.78%    Validation Error: 10.22%\n",
      "Fold: 4    Train Error: 12.26%    Validation Error: 5.60%\n",
      "Fold: 5    Train Error: 13.33%    Validation Error: 12.01%\n",
      "Fold: 6    Train Error: 14.83%    Validation Error: 9.98%\n",
      "Fold: 7    Train Error: 14.70%    Validation Error: 8.07%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 14.72%(1.32%) Validation Error: 9.56%(2.04%)\n",
      "Best model complexity: [18, 12, 6]\n",
      "Test Error of the best model: 7.14%\n"
     ]
    }
   ],
   "source": [
    "# Implementation and exploration.\n",
    "\n",
    "# Main function to run the experiment\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    df = load_and_shuffle_data(\"agaricus-lepiota.data\")\n",
    "    X, y, X_dict = prepare_features_labels(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    data_dicts = format_for_tensorflow(X_train, X_test)\n",
    "\n",
    "    # Create folds for cross-validation\n",
    "    folds = 8\n",
    "    X_folds, y_folds = create_folds(data_dicts[\"train\"], y_train.values, folds)\n",
    "\n",
    "    # Define model complexities\n",
    "    complexities = [\n",
    "        [6], [12, 6],[18, 12, 6],\n",
    "    ]\n",
    "\n",
    "    # Experiment with models\n",
    "    activation, optimizer, loss_fn, epochs = 'tanh', 'sgd', 'mean_squared_error', 2\n",
    "    best_model, best_complexity = run_cross_validation(complexities, X_folds, y_folds, activation, optimizer, loss_fn, epochs, X_train, folds)\n",
    "\n",
    "    # Evaluate best model\n",
    "    print(f\"Best model complexity: {best_complexity}\")\n",
    "    test_acc = test_model(best_model, data_dicts[\"test\"], y_test)\n",
    "    test_err = 100 * (1 - test_acc)\n",
    "    print(f\"Test Error of the best model: {test_err:.2f}%\")\n",
    "\n",
    "# Run the experiment\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model with layers: [6]\n",
      "Fold: 0    Train Error: 4.62%    Validation Error: 0.98%\n",
      "Fold: 1    Train Error: 4.12%    Validation Error: 1.29%\n",
      "Fold: 2    Train Error: 6.00%    Validation Error: 2.34%\n",
      "Fold: 3    Train Error: 5.45%    Validation Error: 2.22%\n",
      "Fold: 4    Train Error: 6.72%    Validation Error: 1.35%\n",
      "Fold: 5    Train Error: 4.28%    Validation Error: 0.99%\n",
      "Fold: 6    Train Error: 4.63%    Validation Error: 1.91%\n",
      "Fold: 7    Train Error: 6.52%    Validation Error: 3.45%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 5.29%(0.96%) Validation Error: 1.82%(0.79%)\n",
      "\n",
      "Evaluating model with layers: [12, 6]\n",
      "Fold: 0    Train Error: 3.22%    Validation Error: 0.49%\n",
      "Fold: 1    Train Error: 3.59%    Validation Error: 0.68%\n",
      "Fold: 2    Train Error: 3.35%    Validation Error: 1.35%\n",
      "Fold: 3    Train Error: 2.60%    Validation Error: 0.25%\n",
      "Fold: 4    Train Error: 3.06%    Validation Error: 0.43%\n",
      "Fold: 5    Train Error: 4.81%    Validation Error: 0.92%\n",
      "Fold: 6    Train Error: 5.19%    Validation Error: 2.03%\n",
      "Fold: 7    Train Error: 4.19%    Validation Error: 1.05%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 3.75%(0.84%) Validation Error: 0.90%(0.54%)\n",
      "\n",
      "Evaluating model with layers: [18, 12, 6]\n",
      "Fold: 0    Train Error: 2.72%    Validation Error: 0.12%\n",
      "Fold: 1    Train Error: 1.35%    Validation Error: 0.43%\n",
      "Fold: 2    Train Error: 2.37%    Validation Error: 0.25%\n",
      "Fold: 3    Train Error: 2.13%    Validation Error: 0.12%\n",
      "Fold: 4    Train Error: 1.80%    Validation Error: 0.06%\n",
      "Fold: 5    Train Error: 2.69%    Validation Error: 0.06%\n",
      "Fold: 6    Train Error: 3.09%    Validation Error: 0.86%\n",
      "Fold: 7    Train Error: 3.37%    Validation Error: 0.62%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 2.44%(0.62%) Validation Error: 0.32%(0.28%)\n",
      "Best model complexity: [18, 12, 6]\n",
      "Test Error of the best model: 0.25%\n"
     ]
    }
   ],
   "source": [
    "# Main function to run the experiment\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    df = load_and_shuffle_data(\"agaricus-lepiota.data\")\n",
    "    X, y, X_dict = prepare_features_labels(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    data_dicts = format_for_tensorflow(X_train, X_test)\n",
    "\n",
    "    # Create folds for cross-validation\n",
    "    folds = 8\n",
    "    X_folds, y_folds = create_folds(data_dicts[\"train\"], y_train.values, folds)\n",
    "\n",
    "    # Define model complexities\n",
    "    complexities = [\n",
    "        [6], [12, 6],[18, 12, 6],\n",
    "    ]\n",
    "\n",
    "    # Experiment with models\n",
    "    activation, optimizer, loss_fn, epochs = 'tanh', 'rmsprop', 'mean_squared_error', 2\n",
    "    best_model, best_complexity = run_cross_validation(complexities, X_folds, y_folds, activation, optimizer, loss_fn, epochs, X_train, folds)\n",
    "\n",
    "    # Evaluate best model\n",
    "    print(f\"Best model complexity: {best_complexity}\")\n",
    "    test_acc = test_model(best_model, data_dicts[\"test\"], y_test)\n",
    "    test_err = 100 * (1 - test_acc)\n",
    "    print(f\"Test Error of the best model: {test_err:.2f}%\")\n",
    "\n",
    "# Run the experiment\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Comparison of Three Experiments with Different Activation Functions and Optimizers\n",
    "\n",
    "In this final comparison, we analyze the impact of changing activation functions and optimizers across three experiments, using three different model architectures: [6], [12, 6], and [18, 12, 6]. The key factors compared are:\n",
    "\n",
    "- **Activation Functions**: `relu`, `tanh`, and variations of optimizers.\n",
    "- **Optimizers**: `adam`, `sgd`, and `rmsprop`.\n",
    "\n",
    "### **Experiment 1: `relu` and `adam`**\n",
    "- **Activation Function**: `relu`\n",
    "- **Optimizer**: `adam`\n",
    "- **Best Model Complexity**: [18, 12, 6]\n",
    "- **Test Error**: 0.00% (perfect performance)\n",
    "\n",
    "#### Key Performance Metrics:\n",
    "- **[6] Architecture**: Mean Validation Error = 3.39% (Std. Dev. = 1.03%)\n",
    "- **[12, 6] Architecture**: Mean Validation Error = 1.06% (Std. Dev. = 0.32%)\n",
    "- **[18, 12, 6] Architecture**: Mean Validation Error = 0.38% (Std. Dev. = 0.23%)\n",
    "\n",
    "### **Experiment 2: `tanh` and `sgd`**\n",
    "- **Activation Function**: `tanh`\n",
    "- **Optimizer**: `sgd`\n",
    "- **Best Model Complexity**: [18, 12, 6]\n",
    "- **Test Error**: 7.14%\n",
    "\n",
    "#### Key Performance Metrics:\n",
    "- **[6] Architecture**: Mean Validation Error = 9.81% (Std. Dev. = 2.45%)\n",
    "- **[12, 6] Architecture**: Mean Validation Error = 10.29% (Std. Dev. = 1.99%)\n",
    "- **[18, 12, 6] Architecture**: Mean Validation Error = 9.56% (Std. Dev. = 2.04%)\n",
    "\n",
    "### **Experiment 3: `tanh` and `rmsprop`**\n",
    "- **Activation Function**: `tanh`\n",
    "- **Optimizer**: `rmsprop`\n",
    "- **Best Model Complexity**: [18, 12, 6]\n",
    "- **Test Error**: 0.25%\n",
    "\n",
    "#### Key Performance Metrics:\n",
    "- **[6] Architecture**: Mean Validation Error = 1.82% (Std. Dev. = 0.79%)\n",
    "- **[12, 6] Architecture**: Mean Validation Error = 0.90% (Std. Dev. = 0.54%)\n",
    "- **[18, 12, 6] Architecture**: Mean Validation Error = 0.32% (Std. Dev. = 0.28%)\n",
    "\n",
    "### **Summary of Findings:**\n",
    "\n",
    "1. **Effect of Activation Functions**:\n",
    "   - **`relu` vs `tanh`**: The models with `relu` activation performed significantly better in terms of both training and validation errors in Experiment 1. `relu` provided better results than `tanh` across all architectures.\n",
    "   - **`tanh`** showed higher errors compared to `relu`, indicating that the simpler, non-saturating nature of `relu` is better suited for this dataset.\n",
    "\n",
    "2. **Effect of Optimizers**:\n",
    "   - **`adam`** (Experiment 1) was the most successful optimizer, achieving **perfect performance (0% test error)** for the best architecture ([18, 12, 6]).\n",
    "   - **`sgd`** (Experiment 2) performed the worst, with a test error of **7.14%**. `sgd` is less adaptive and struggles to achieve as low a test error as `adam`.\n",
    "   - **`rmsprop`** (Experiment 3) showed promising results, achieving a **test error of 0.25%**, which is very close to `adam`, suggesting that both `rmsprop` and `adam` are more effective optimizers than `sgd`.\n",
    "\n",
    "3. **Model Complexity**:\n",
    "   - The **[18, 12, 6] architecture** performed best in all three experiments, with the lowest validation errors and highest consistency across folds. This indicates that a deeper, more complex model can generalize better in this case.\n",
    "   - The **[6]** architecture consistently had the highest validation errors, and the **[12, 6]** architecture performed slightly better but still did not outperform the deeper [18, 12, 6] architecture.\n",
    "\n",
    "### **Final Conclusion**:\n",
    "- **Best Performance**: The best model was the **[18, 12, 6] architecture** with **`relu` activation** and **`adam` optimizer**, achieving **perfect performance on the test set (0.00% error)**.\n",
    "- **Second Best Performance**: The second-best configuration was with **`tanh` activation** and **`rmsprop` optimizer**, achieving a **test error of 0.25%**. This combination performed well but was still outperformed by `adam`.\n",
    "- **Worst Performance**: The worst-performing configuration was with **`tanh` activation** and **`sgd` optimizer**, which resulted in a **test error of 7.14%**.\n",
    "\n",
    "Thus, **`relu` activation** and **`adam` optimizer** in the **[18, 12, 6]** model is the best combination for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJDsC809yqTw"
   },
   "source": [
    "## OPTIONAL. BONUS. Experiment: Loss Function\n",
    "\n",
    "Modify the loss function of any chosen model.\n",
    "\n",
    "Explain the motivation behind the modifications you made.\n",
    "\n",
    "Explore the effects on the performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9zavtQjCy7Ud"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model with layers: [6]\n",
      "Fold: 0    Train Error: 9.80%    Validation Error: 3.57%\n",
      "Fold: 1    Train Error: 8.13%    Validation Error: 2.77%\n",
      "Fold: 2    Train Error: 8.70%    Validation Error: 2.52%\n",
      "Fold: 3    Train Error: 14.24%    Validation Error: 3.45%\n",
      "Fold: 4    Train Error: 5.35%    Validation Error: 1.91%\n",
      "Fold: 5    Train Error: 8.73%    Validation Error: 4.25%\n",
      "Fold: 6    Train Error: 11.80%    Validation Error: 4.19%\n",
      "Fold: 7    Train Error: 9.60%    Validation Error: 5.36%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 9.54%(2.46%) Validation Error: 3.50%(1.03%)\n",
      "\n",
      "Evaluating model with layers: [12, 6]\n",
      "Fold: 0    Train Error: 6.42%    Validation Error: 1.11%\n",
      "Fold: 1    Train Error: 4.56%    Validation Error: 0.92%\n",
      "Fold: 2    Train Error: 3.90%    Validation Error: 0.98%\n",
      "Fold: 3    Train Error: 7.61%    Validation Error: 1.11%\n",
      "Fold: 4    Train Error: 7.32%    Validation Error: 0.37%\n",
      "Fold: 5    Train Error: 4.84%    Validation Error: 1.05%\n",
      "Fold: 6    Train Error: 8.89%    Validation Error: 0.92%\n",
      "Fold: 7    Train Error: 4.55%    Validation Error: 1.42%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 6.01%(1.69%) Validation Error: 0.98%(0.28%)\n",
      "\n",
      "Evaluating model with layers: [18, 12, 6]\n",
      "Fold: 0    Train Error: 3.75%    Validation Error: 0.43%\n",
      "Fold: 1    Train Error: 5.21%    Validation Error: 0.37%\n",
      "Fold: 2    Train Error: 9.15%    Validation Error: 0.43%\n",
      "Fold: 3    Train Error: 5.49%    Validation Error: 0.49%\n",
      "Fold: 4    Train Error: 4.26%    Validation Error: 0.12%\n",
      "Fold: 5    Train Error: 7.62%    Validation Error: 2.28%\n",
      "Fold: 6    Train Error: 7.32%    Validation Error: 0.86%\n",
      "Fold: 7    Train Error: 6.79%    Validation Error: 1.05%\n",
      "\n",
      "Mean(Std. Dev.) over all folds for this model:\n",
      "-------------------------------\n",
      "Train Error: 6.20%(1.72%) Validation Error: 0.75%(0.64%)\n",
      "Best model complexity: [18, 12, 6]\n",
      "Test Error of the best model: 0.12%\n"
     ]
    }
   ],
   "source": [
    "# Implementation and exploration.\n",
    "# Main function to run the experiment\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    df = load_and_shuffle_data(\"agaricus-lepiota.data\")\n",
    "    X, y, X_dict = prepare_features_labels(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    data_dicts = format_for_tensorflow(X_train, X_test)\n",
    "\n",
    "    # Create folds for cross-validation\n",
    "    folds = 8\n",
    "    X_folds, y_folds = create_folds(data_dicts[\"train\"], y_train.values, folds)\n",
    "\n",
    "    # Define model complexities\n",
    "    complexities = [\n",
    "        [6], [12, 6],[18, 12, 6],\n",
    "    ]\n",
    "\n",
    "    # Experiment with models\n",
    "    activation, optimizer, loss_fn, epochs = 'relu', 'adam', 'binary_crossentropy', 2\n",
    "    best_model, best_complexity = run_cross_validation(complexities, X_folds, y_folds, activation, optimizer, loss_fn, epochs, X_train, folds)\n",
    "\n",
    "    # Evaluate best model\n",
    "    print(f\"Best model complexity: {best_complexity}\")\n",
    "    test_acc = test_model(best_model, data_dicts[\"test\"], y_test)\n",
    "    test_err = 100 * (1 - test_acc)\n",
    "    print(f\"Test Error of the best model: {test_err:.2f}%\")\n",
    "\n",
    "# Run the experiment\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Comparison with Previous Experiment (Binary Crossentropy):\n",
    "\n",
    "1. **Validation Error:**\n",
    "   - **Mean Squared Error:** The best model with complexity `[18, 12, 6]` achieved a validation error of **0.38%**, which is still low but higher than the **0.12%** achieved when using `binary_crossentropy`.\n",
    "   - **Binary Crossentropy:** The validation error for the best model with complexity `[18, 12, 6]` was **0.75%**. So, both loss functions seem to yield quite similar results, but `binary_crossentropy` led to marginally higher validation error.\n",
    "\n",
    "2. **Test Error:**\n",
    "   - **Mean Squared Error:** The test error for the best model (`[18, 12, 6]`) was **0.00%**, which indicates perfect performance on the test set.\n",
    "   - **Binary Crossentropy:** The test error for the best model was **0.12%**, which is still excellent but slightly higher than the model trained with mean squared error.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "- **Best Model Complexity:** Both experiments suggest that **`[18, 12, 6]`** is the best model complexity, showing the lowest validation and test errors in both cases.\n",
    "- **Loss Function Impact:**\n",
    "  - **Mean Squared Error**: Provided perfect test performance (0.00% test error) and very low validation error, but it slightly outperformed `binary_crossentropy` on the test set.\n",
    "  - **Binary Crossentropy**: Although the performance was slightly worse on the test set, it still produced excellent results, and the validation error was very close to that of mean squared error.\n",
    "  \n",
    "Overall, **Mean Squared Error** showed marginally better performance, but the choice of loss function can depend on the problem specifics, and both loss functions resulted in very low error rates in this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMCU5PBHz8DF"
   },
   "source": [
    "No other directions for this assignment, other than what's here and in the \"General Directions\" section. You have a lot of freedom with this assignment. Don't get carried away. It is expected the results may vary, being better or worse, due to the limitations of the dataset. Graders are not going to run your notebooks. The notebook will be read as a report on how different models were explored. Since you'll be using libraries, the emphasis will be on your ability to communicate your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VfoAYAQtw4M"
   },
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
